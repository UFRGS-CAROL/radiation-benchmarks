const char *kernel_fft_ocl =
"// -*- c++ -*-\n"
"\n"
"// This code uses algorithm described in:\n"
"// \"Fitting FFT onto G80 Architecture\". Vasily Volkov and Brian Kazian, UC Berkeley CS258 project report. May 2008.\n"
"#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable\n"
"#pragma OPENCL EXTENSION cl_khr_fp64: enable\n"
"//#pragma OPENCL EXTENSION cl_nv_compiler_options: enable\n"
"\n"
"#ifndef M_PI\n"
"# define M_PI 3.14159265358979323846f\n"
"#endif\n"
"\n"
"#ifndef M_SQRT1_2\n"
"# define M_SQRT1_2      0.70710678118654752440f\n"
"#endif\n"
"\n"
"\n"
"#define exp_1_8   (double2)(  1, -1 )//requires post-multiply by 1/sqrt(2)\n"
"#define exp_1_4   (double2)(  0, -1 )\n"
"#define exp_3_8   (double2)( -1, -1 )//requires post-multiply by 1/sqrt(2)\n"
"\n"
"#define iexp_1_8   (double2)(  1, 1 )//requires post-multiply by 1/sqrt(2)\n"
"#define iexp_1_4   (double2)(  0, 1 )\n"
"#define iexp_3_8   (double2)( -1, 1 )//requires post-multiply by 1/sqrt(2)\n"
"\n"
"\n"
"inline void globalLoads8(double2 *data, __global double2 *in, int stride) {\n"
"    for( int i = 0; i < 8; i++ )\n"
"        data[i] = in[i*stride];\n"
"}\n"
"\n"
"// Stores the data back to main array, this function should be called in \n"
"// the middle of execution when the work is distributted. This way the second\n"
"// device can catch up the corrected data computed so far\n"
"inline void globalStoresMiddle(double2 *data, __global double2 *out, int stride) {\n"
"    for( int i = 0; i < 8; i++ )\n"
"        out[i*stride] = data[i];\n"
"}\n"
"\n"
"// This function should be called only when the FFT execution is finished by \n"
"// all the devices\n"
"inline void globalStores8(double2 *data, __global double2 *out, int stride) {\n"
"    int reversed[] = {0,4,2,6,1,5,3,7};\n"
"\n"
"//#pragma unroll\n"
"    for( int i = 0; i < 8; i++ )\n"
"        out[i*stride] = data[reversed[i]];\n"
"}\n"
"\n"
"inline void storex8( double2 *a, __local double *x, int sx ) {\n"
"    int reversed[] = {0,4,2,6,1,5,3,7};\n"
"\n"
"//#pragma unroll\n"
"    for( int i = 0; i < 8; i++ )\n"
"        x[i*sx] = a[reversed[i]].x;\n"
"}\n"
"\n"
"inline void storey8( double2 *a, __local double *x, int sx ) {\n"
"    int reversed[] = {0,4,2,6,1,5,3,7};\n"
"\n"
"//#pragma unroll\n"
"    for( int i = 0; i < 8; i++ )\n"
"        x[i*sx] = a[reversed[i]].y;\n"
"}\n"
"\n"
"\n"
"inline void loadx8( double2 *a, __local double *x, int sx ) {\n"
"    for( int i = 0; i < 8; i++ )\n"
"        a[i].x = x[i*sx];\n"
"}\n"
"\n"
"inline void loady8( double2 *a, __local double *x, int sx ) {\n"
"    for( int i = 0; i < 8; i++ )\n"
"        a[i].y = x[i*sx];\n"
"}\n"
"\n"
"\n"
"#define transpose( a, s, ds, l, dl, sync )                              \\\n"
"{                                                                       \\\n"
"    storex8( a, s, ds );  if( (sync)&8 ) barrier(CLK_LOCAL_MEM_FENCE);  \\\n"
"    loadx8 ( a, l, dl );  if( (sync)&4 ) barrier(CLK_LOCAL_MEM_FENCE);  \\\n"
"    storey8( a, s, ds );  if( (sync)&2 ) barrier(CLK_LOCAL_MEM_FENCE);  \\\n"
"    loady8 ( a, l, dl );  if( (sync)&1 ) barrier(CLK_LOCAL_MEM_FENCE);  \\\n"
"}\n"
"\n"
"inline double2 exp_i( double phi ) {\n"
"//#ifdef USE_NATIVE\n"
"//    return (double2)( native_cos(phi), native_sin(phi) );\n"
"//#else\n"
"    return (double2)( cos(phi), sin(phi) );\n"
"//#endif\n"
"}\n"
"\n"
"inline double2 cmplx_mul( double2 a, double2 b ) {\n"
"    return (double2)( a.x*b.x-a.y*b.y, a.x*b.y+a.y*b.x );\n"
"}\n"
"inline double2 cm_fl_mul( double2 a, double  b ) {\n"
"    return (double2)( b*a.x, b*a.y );\n"
"}\n"
"inline double2 cmplx_add( double2 a, double2 b ) {\n"
"    return (double2)( a.x + b.x, a.y + b.y );\n"
"}\n"
"inline double2 cmplx_sub( double2 a, double2 b ) {\n"
"    return (double2)( a.x - b.x, a.y - b.y );\n"
"}\n"
"\n"
"\n"
"#define twiddle8(a, i, n )                                              \\\n"
"{                                                                       \\\n"
"    int reversed8[] = {0,4,2,6,1,5,3,7};                                \\\n"
"    for( int j = 1; j < 8; j++ ){                                       \\\n"
"        a[j] = cmplx_mul( a[j],exp_i((-2*M_PI*reversed8[j]/(n))*(i)) ); \\\n"
"    }                                                                   \\\n"
"}\n"
"\n"
"#define FFT2(a0, a1)                            \\\n"
"{                                               \\\n"
"    double2 c0 = *a0;                           \\\n"
"    *a0 = cmplx_add(c0,*a1);                    \\\n"
"    *a1 = cmplx_sub(c0,*a1);                    \\\n"
"}\n"
"\n"
"#define FFT4(a0, a1, a2, a3)                    \\\n"
"{                                               \\\n"
"    FFT2( a0, a2 );                             \\\n"
"    FFT2( a1, a3 );                             \\\n"
"    *a3 = cmplx_mul(*a3,exp_1_4);               \\\n"
"    FFT2( a0, a1 );                             \\\n"
"    FFT2( a2, a3 );                             \\\n"
"}\n"
"\n"
"#define FFT8(a)                                                 \\\n"
"{                                                               \\\n"
"    FFT2( &a[0], &a[4] );                                       \\\n"
"    FFT2( &a[1], &a[5] );                                       \\\n"
"    FFT2( &a[2], &a[6] );                                       \\\n"
"    FFT2( &a[3], &a[7] );                                       \\\n"
"                                                                \\\n"
"    a[5] = cm_fl_mul( cmplx_mul(a[5],exp_1_8) , M_SQRT1_2 );    \\\n"
"    a[6] =  cmplx_mul( a[6] , exp_1_4);                         \\\n"
"    a[7] = cm_fl_mul( cmplx_mul(a[7],exp_3_8) , M_SQRT1_2 );    \\\n"
"                                                                \\\n"
"    FFT4( &a[0], &a[1], &a[2], &a[3] );                         \\\n"
"    FFT4( &a[4], &a[5], &a[6], &a[7] );                         \\\n"
"}\n"
"\n"
"#define itwiddle8( a, i, n )                                            \\\n"
"{                                                                       \\\n"
"    int reversed8[] = {0,4,2,6,1,5,3,7};                                \\\n"
"    for( int j = 1; j < 8; j++ )                                        \\\n"
"        a[j] = cmplx_mul(a[j] , exp_i((2*M_PI*reversed8[j]/(n))*(i)) ); \\\n"
"}\n"
"\n"
"#define IFFT2 FFT2\n"
"\n"
"#define IFFT4( a0, a1, a2, a3 )                 \\\n"
"{                                               \\\n"
"    IFFT2( a0, a2 );                            \\\n"
"    IFFT2( a1, a3 );                            \\\n"
"    *a3 = cmplx_mul(*a3 , iexp_1_4);            \\\n"
"    IFFT2( a0, a1 );                            \\\n"
"    IFFT2( a2, a3);                             \\\n"
"}\n"
"\n"
"#define IFFT8( a )                                              \\\n"
"{                                                               \\\n"
"    IFFT2( &a[0], &a[4] );                                      \\\n"
"    IFFT2( &a[1], &a[5] );                                      \\\n"
"    IFFT2( &a[2], &a[6] );                                      \\\n"
"    IFFT2( &a[3], &a[7] );                                      \\\n"
"                                                                \\\n"
"    a[5] = cm_fl_mul( cmplx_mul(a[5],iexp_1_8) , M_SQRT1_2 );   \\\n"
"    a[6] = cmplx_mul( a[6] , iexp_1_4);                         \\\n"
"    a[7] = cm_fl_mul( cmplx_mul(a[7],iexp_3_8) , M_SQRT1_2 );   \\\n"
"                                                                \\\n"
"    IFFT4( &a[0], &a[1], &a[2], &a[3] );                        \\\n"
"    IFFT4( &a[4], &a[5], &a[6], &a[7] );                        \\\n"
"}\n"
"\n"
"///////////////////////////////////////////\n"
"\n"
"//distr = 0,   0%  cpu | gpu 100%\n"
"//distr = 1,  33%  cpu | gpu  66%\n"
"//distr = 2,  66%  cpu | gpu  33%\n"
"//distr = 3, 100%  cpu | gpu   0%\n"
"__kernel void fft1D_512 (__global double2 *work, int distr, int fromGPU)\n"
"{\n"
"\n"
"    int tid = get_local_id(0);\n"
"    int blockIdx = get_group_id(0) * 512 + tid;\n"
"    int hi = tid>>3;\n"
"    int lo = tid&7;\n"
"    double2 data[8];\n"
"    __local double smem[8*8*9];\n"
"    work = work + blockIdx;\n"
"\n"
"    // CPU running\n"
"    if(fromGPU == 0) {\n"
"        switch(distr) {\n"
"            // 0% CPU, 100% GPU\n"
"        case 0:\n"
"            // do nothing\n"
"            break;\n"
"\n"
"            // 33% CPU, 66% GPU\n"
"        case 1:\n"
"            // CPU execute after GPU, therefore execute last_33%\n"
"            globalLoads8(data, work, 64);\n"
"            FFT8( data );\n"
"            globalStores8(data, work, 64);\n"
"            break;\n"
"            // 66% CPU, 33% GPU\n"
"        case 2:\n"
"            // CPU execute after GPU, therefore execute last_66%\n"
"            globalLoads8(data, work, 64);\n"
"            twiddle8( data, tid, 512 );\n"
"            transpose(data, &smem[hi*8+lo], 66, &smem[lo*66+hi], 8, 0xf);\n"
"            FFT8( data );\n"
"            twiddle8( data, hi, 64 );\n"
"            transpose(data, &smem[hi*8+lo], 8*9, &smem[hi*8*9+lo], 8, 0xE);\n"
"            FFT8( data );\n"
"            globalStores8(data, work, 64);\n"
"            break;\n"
"            // 100% CPU, 0% GPU\n"
"        case 3:\n"
"            globalLoads8(data, work, 64);\n"
"            FFT8( data );\n"
"            twiddle8( data, tid, 512 );\n"
"            transpose(data, &smem[hi*8+lo], 66, &smem[lo*66+hi], 8, 0xf);\n"
"            FFT8( data );\n"
"            twiddle8( data, hi, 64 );\n"
"            transpose(data, &smem[hi*8+lo], 8*9, &smem[hi*8*9+lo], 8, 0xE);\n"
"            FFT8( data );\n"
"            globalStores8(data, work, 64);\n"
"            break;\n"
"        }\n"
"    }\n"
"    // GPU running\n"
"    else if(fromGPU == 1) {\n"
"        switch(distr) {\n"
"            // 0% CPU, 100% GPU\n"
"        case 0:\n"
"            globalLoads8(data, work, 64);\n"
"            FFT8( data );\n"
"            twiddle8( data, tid, 512 );\n"
"            transpose(data, &smem[hi*8+lo], 66, &smem[lo*66+hi], 8, 0xf);\n"
"            FFT8( data );\n"
"            twiddle8( data, hi, 64 );\n"
"            transpose(data, &smem[hi*8+lo], 8*9, &smem[hi*8*9+lo], 8, 0xE);\n"
"            FFT8( data );\n"
"            globalStores8(data, work, 64);\n"
"            break;\n"
"\n"
"            // 33% CPU, 66% GPU\n"
"        case 1:\n"
"            // CPU execute after GPU, therefore execute first_66%\n"
"            globalLoads8(data, work, 64);\n"
"            FFT8( data );\n"
"            twiddle8( data, tid, 512 );\n"
"            transpose(data, &smem[hi*8+lo], 66, &smem[lo*66+hi], 8, 0xf);\n"
"            FFT8( data );\n"
"            twiddle8( data, hi, 64 );\n"
"            transpose(data, &smem[hi*8+lo], 8*9, &smem[hi*8*9+lo], 8, 0xE);\n"
"            globalStoresMiddle(data, work, 64);\n"
"            //globalStores8(data, work, 64);\n"
"            break;\n"
"            // 66% CPU, 33% GPU\n"
"        case 2:\n"
"            // CPU execute after GPU, therefore execute first_33%\n"
"            globalLoads8(data, work, 64);\n"
"            FFT8( data );\n"
"            globalStoresMiddle(data, work, 64);\n"
"            //globalStores8(data, work, 64);\n"
"            break;\n"
"            // 100% CPU, 0% GPU\n"
"        case 3:\n"
"            // do nothing\n"
"            break;\n"
"        }\n"
"    }\n"
"}\n"
"__kernel void ifft1D_512 (__global double2 *work, int distr, int fromGPU)\n"
"{\n"
"    //work[0].x = 666;\n"
"    int i;\n"
"    int tid = get_local_id(0);\n"
"    int blockIdx = get_group_id(0) * 512 + tid;\n"
"    int hi = tid>>3;\n"
"    int lo = tid&7;\n"
"    double2 data[8];\n"
"    __local double smem[8*8*9];\n"
"\n"
"    // starting index of data to/from global memory\n"
"    work = work + blockIdx;\n"
"    globalLoads8(data, work, 64); // coalesced global reads\n"
"\n"
"    // Inject an artificial error for testing the sensitivity of FFT\n"
"    // if( blockIdx == 0 ){ data[6] *= 1.001; }\n"
"\n"
"    IFFT8( data );\n"
"\n"
"    itwiddle8( data, tid, 512 );\n"
"    transpose(data, &smem[hi*8+lo], 66, &smem[lo*66+hi], 8, 0xf);\n"
"\n"
"    IFFT8( data );\n"
"\n"
"    itwiddle8( data, hi, 64 );\n"
"    transpose(data, &smem[hi*8+lo], 8*9, &smem[hi*8*9+lo], 8, 0xE);\n"
"\n"
"    IFFT8( data );\n"
"\n"
"    for(i=0; i<8; i++) {\n"
"        data[i].x = data[i].x/512.0f;\n"
"        data[i].y = data[i].y/512.0f;\n"
"    }\n"
"\n"
"    globalStores8(data, work, 64);\n"
"\n"
"}\n"
"\n"
"\n"
"__kernel void\n"
"chk1D_512(__global double2* work, int half_n_cmplx, __global int* fail)\n"
"{\n"
"    int i, tid = get_local_id(0);\n"
"    int blockIdx = get_group_id(0) * 512 + tid;\n"
"    double2 a[8], b[8];\n"
"\n"
"    work = work + blockIdx;\n"
"\n"
"    for (i = 0; i < 8; i++) {\n"
"        a[i] = work[i*64];\n"
"    }\n"
"\n"
"    for (i = 0; i < 8; i++) {\n"
"        b[i] = work[half_n_cmplx+i*64];\n"
"    }\n"
"\n"
"    for (i = 0; i < 8; i++) {\n"
"        if (a[i].x != b[i].x || a[i].y != b[i].y) {\n"
"            *fail = 1;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"__kernel void\n"
"GoldChk(__global double2* gold, __global double2* resultCPU, int N, __global int* kerrors, double AVOIDZERO, double ACCEPTDIFF)\n"
"{\n"
"        int i = get_global_id(0);\n"
"\n"
"	\n"
"        if ((fabs(gold[i].x)>AVOIDZERO)&&\n"
"        ((fabs((resultCPU[i].x-gold[i].x)/resultCPU[i].x)>ACCEPTDIFF)||\n"
"         (fabs((resultCPU[i].x-gold[i].x)/gold[i].x)>ACCEPTDIFF))) {\n"
"		    atomic_inc(kerrors);\n"
"	    }\n"
"\n"
"        if ((fabs(gold[i].y)>AVOIDZERO)&&\n"
"        ((fabs((resultCPU[i].y-gold[i].y)/resultCPU[i].y)>ACCEPTDIFF)||\n"
"         (fabs((resultCPU[i].y-gold[i].y)/gold[i].y)>ACCEPTDIFF))) {\n"
"		    atomic_inc(kerrors);\n"
"	    }\n"
"\n"
"}\n"
;
