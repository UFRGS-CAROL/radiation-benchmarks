const char *kernel_lavamd_ocl =
"\n"
"#define fp float\n"
"\n"
"#define NUMBER_PAR_PER_BOX 100							// keep this low to allow more blocks that share shared memory to run concurrently, code does not work for larger than 110, more speedup can be achieved with larger number and no shared memory used\n"
"\n"
"\n"
"#define DOT(A,B) ((A.x)*(B.x)+(A.y)*(B.y)+(A.z)*(B.z))	// STABLE\n"
"\n"
"\n"
"typedef struct\n"
"{\n"
"	fp x, y, z;\n"
"\n"
"} THREE_VECTOR;\n"
"\n"
"typedef struct\n"
"{\n"
"	fp v, x, y, z;\n"
"\n"
"} FOUR_VECTOR;\n"
"\n"
"typedef struct nei_str\n"
"{\n"
"\n"
"	// neighbor box\n"
"	int x, y, z;\n"
"	int number;\n"
"	long offset;\n"
"\n"
"} nei_str;\n"
"\n"
"typedef struct box_str\n"
"{\n"
"\n"
"	// home box\n"
"	int x, y, z;\n"
"	int number;\n"
"	long offset;\n"
"\n"
"	// neighbor boxes\n"
"	int nn;\n"
"	nei_str nei[26];\n"
"\n"
"} box_str;\n"
"\n"
"typedef struct par_str\n"
"{\n"
"\n"
"	fp alpha;\n"
"\n"
"} par_str;\n"
"\n"
"typedef struct dim_str\n"
"{\n"
"\n"
"	// input arguments\n"
"	int cur_arg;\n"
"	int arch_arg;\n"
"	int cores_arg;\n"
"	int boxes1d_arg;\n"
"\n"
"	// system memory\n"
"	long number_boxes;\n"
"	long box_mem;\n"
"	long space_elem;\n"
"	long space_mem;\n"
"	long space_mem2;\n"
"\n"
"} dim_str;\n"
"\n"
"\n"
"__kernel void kernel_gpu_opencl(	par_str d_par_gpu,\n"
"					dim_str d_dim_gpu,\n"
"					__global box_str *d_box_gpu,\n"
"					__global FOUR_VECTOR *d_rv_gpu,\n"
"					__global fp *d_qv_gpu,\n"
"					__global FOUR_VECTOR *d_fv_gpu,\n"
"					int number_threads)\n"
"{\n"
"\n"
"	//	THREAD PARAMETERS\n"
"\n"
"	int bx = get_group_id(0);															// get current horizontal block index (0-n)\n"
"	int tx = get_local_id(0);															// get current horizontal thread index (0-n)\n"
"	int wtx = tx;\n"
"\n"
"	//	DO FOR THE NUMBER OF BOXES\n"
"\n"
"	if(bx<d_dim_gpu.number_boxes){\n"
"\n"
"		//	Extract input parameters\n"
"\n"
"		// parameters\n"
"		fp a2 = 2*d_par_gpu.alpha*d_par_gpu.alpha;\n"
"\n"
"		// home box\n"
"		int first_i;\n"
"		// (enable the line below only if wanting to use shared memory)\n"
"		__local FOUR_VECTOR rA_shared[100];\n"
"\n"
"		// nei box\n"
"		int pointer;\n"
"		int k = 0;\n"
"		int first_j;\n"
"		int j = 0;\n"
"		// (enable the two lines below only if wanting to use shared memory)\n"
"		__local FOUR_VECTOR rB_shared[100];\n"
"		__local fp qB_shared[100];\n"
"\n"
"		// common\n"
"		fp r2;\n"
"		fp u2;\n"
"		fp vij;\n"
"		fp fs;\n"
"		fp fxij;\n"
"		fp fyij;\n"
"		fp fzij;\n"
"		THREE_VECTOR d;\n"
"\n"
"		//	Home box\n"
"\n"
"		//	Setup parameters\n"
"\n"
"		// home box - box parameters\n"
"		first_i = d_box_gpu[bx].offset;\n"
"\n"
"		//	Copy to shared memory\n"
"\n"
"		// (enable the section below only if wanting to use shared memory)\n"
"		// home box - shared memory\n"
"		while(wtx<NUMBER_PAR_PER_BOX){\n"
"			rA_shared[wtx] = d_rv_gpu[first_i+wtx];\n"
"			wtx = wtx + number_threads;\n"
"		}\n"
"		wtx = tx;\n"
"\n"
"		// (enable the section below only if wanting to use shared memory)\n"
"		// synchronize threads  - not needed, but just to be safe for now\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"\n"
"		//	nei box loop\n"
"\n"
"		// loop over nei boxes of home box\n"
"		for (k=0; k<(1+d_box_gpu[bx].nn); k++){\n"
"\n"
"			//----------------------------------------50\n"
"			//	nei box - get pointer to the right box\n"
"			//----------------------------------------50\n"
"\n"
"			if(k==0){\n"
"				pointer = bx;													// set first box to be processed to home box\n"
"			}\n"
"			else{\n"
"				pointer = d_box_gpu[bx].nei[k-1].number;							// remaining boxes are nei boxes\n"
"			}\n"
"\n"
"			//	Setup parameters\n"
"\n"
"			// nei box - box parameters\n"
"			first_j = d_box_gpu[pointer].offset;\n"
"\n"
"			//	Setup parameters\n"
"\n"
"			// (enable the section below only if wanting to use shared memory)\n"
"			// nei box - shared memory\n"
"			while(wtx<NUMBER_PAR_PER_BOX){\n"
"				rB_shared[wtx] = d_rv_gpu[first_j+wtx];\n"
"				qB_shared[wtx] = d_qv_gpu[first_j+wtx];\n"
"				wtx = wtx + number_threads;\n"
"			}\n"
"			wtx = tx;\n"
"\n"
"			// (enable the section below only if wanting to use shared memory)\n"
"			// synchronize threads because in next section each thread accesses data brought in by different threads here\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"\n"
"			//	Calculation\n"
"\n"
"			// loop for the number of particles in the home box\n"
"			while(wtx<NUMBER_PAR_PER_BOX){\n"
"\n"
"				// loop for the number of particles in the current nei box\n"
"				for (j=0; j<NUMBER_PAR_PER_BOX; j++){\n"
"\n"
"					// (disable the section below only if wanting to use shared memory)\n"
"					// r2 = d_rv_gpu[first_i+wtx].v + d_rv_gpu[first_j+j].v - DOT(d_rv_gpu[first_i+wtx],d_rv_gpu[first_j+j]); \n"
"					// u2 = a2*r2;\n"
"					// vij= exp(-u2);\n"
"					// fs = 2*vij;\n"
"					// d.x = d_rv_gpu[first_i+wtx].x  - d_rv_gpu[first_j+j].x;\n"
"					// fxij=fs*d.x;\n"
"					// d.y = d_rv_gpu[first_i+wtx].y  - d_rv_gpu[first_j+j].y;\n"
"					// fyij=fs*d.y;\n"
"					// d.z = d_rv_gpu[first_i+wtx].z  - d_rv_gpu[first_j+j].z;\n"
"					// fzij=fs*d.z;\n"
"					// d_fv_gpu[first_i+wtx].v +=  d_qv_gpu[first_j+j]*vij;\n"
"					// d_fv_gpu[first_i+wtx].x +=  d_qv_gpu[first_j+j]*fxij;\n"
"					// d_fv_gpu[first_i+wtx].y +=  d_qv_gpu[first_j+j]*fyij;\n"
"					// d_fv_gpu[first_i+wtx].z +=  d_qv_gpu[first_j+j]*fzij;\n"
"\n"
"					// (enable the section below only if wanting to use shared memory)\n"
"					r2 = rA_shared[wtx].v + rB_shared[j].v - DOT(rA_shared[wtx],rB_shared[j]); \n"
"					u2 = a2*r2;\n"
"					vij= exp(-u2);\n"
"					fs = 2*vij;\n"
"					d.x = rA_shared[wtx].x  - rB_shared[j].x;\n"
"					fxij=fs*d.x;\n"
"					d.y = rA_shared[wtx].y  - rB_shared[j].y;\n"
"					fyij=fs*d.y;\n"
"					d.z = rA_shared[wtx].z  - rB_shared[j].z;\n"
"					fzij=fs*d.z;\n"
"					d_fv_gpu[first_i+wtx].v +=  qB_shared[j]*vij;\n"
"					d_fv_gpu[first_i+wtx].x +=  qB_shared[j]*fxij;\n"
"					d_fv_gpu[first_i+wtx].y +=  qB_shared[j]*fyij;\n"
"					d_fv_gpu[first_i+wtx].z +=  qB_shared[j]*fzij;\n"
"\n"
"				}\n"
"\n"
"				// increment work thread index\n"
"				wtx = wtx + number_threads;\n"
"\n"
"			}\n"
"\n"
"			// reset work index\n"
"			wtx = tx;\n"
"\n"
"			// synchronize after finishing force contributions from current nei box not to cause conflicts when starting next box\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"\n"
"			//	Calculation END\n"
"\n"
"		}\n"
"\n"
"		//	nei box loop END\n"
"\n"
"	}\n"
"\n"
"}\n"
"\n"
;
